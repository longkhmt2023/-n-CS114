{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8c51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44801b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDigitDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        image_paths = []\n",
    "        for ext in ('*.jpg', '*.jpeg', '*.png', '*.heic', '*.jfif'):\n",
    "            image_paths.extend(glob.glob(os.path.join(root_dir, ext)))\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            basename = os.path.basename(img_path)\n",
    "            label_part = basename.split('_')[0]\n",
    "\n",
    "            # ✅ Kiểm tra nếu label không phải là số thì bỏ qua\n",
    "            if not label_part.isdigit():\n",
    "                raise ValueError(f\"Nhãn không hợp lệ: {label_part}\")\n",
    "\n",
    "            label = int(label_part)\n",
    "\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi đọc ảnh {img_path}: {e}\")\n",
    "            return torch.zeros(3, 32, 32), -1\n",
    "\n",
    "class MyTestDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = [os.path.join(image_dir, fname)\n",
    "                            for fname in os.listdir(image_dir)\n",
    "                            if fname.endswith(('.png', '.jpg', '.jpeg', '*.heic', '*.jfif'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi đọc ảnh {img_path}: {e}\")\n",
    "            return torch.zeros(3, 32, 32), os.path.basename(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, os.path.basename(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c31a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52056504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng ảnh train: 5473\n"
     ]
    }
   ],
   "source": [
    "train_dir = r'D:\\Train2'\n",
    "test_dir = r'D:\\Test\\data.2025'\n",
    "\n",
    "train_dataset = MyDigitDataset(train_dir, transform=transform)\n",
    "print(\"Số lượng ảnh train:\", len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = MyTestDataset(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8fc49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3 * 32 * 32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ANNModel().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994246dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3265\n",
      "Epoch 2, Loss: 2.3044\n",
      "Epoch 3, Loss: 2.2911\n",
      "Epoch 4, Loss: 2.2785\n",
      "Epoch 5, Loss: 2.2611\n",
      "Epoch 6, Loss: 2.2359\n",
      "Epoch 7, Loss: 2.1987\n",
      "Epoch 8, Loss: 2.1703\n",
      "Epoch 9, Loss: 2.1204\n",
      "Epoch 10, Loss: 2.0623\n",
      "Epoch 11, Loss: 2.0239\n",
      "Epoch 12, Loss: 1.9757\n",
      "Epoch 13, Loss: 1.9341\n",
      "Epoch 14, Loss: 1.8866\n",
      "Epoch 15, Loss: 1.8464\n",
      "Epoch 16, Loss: 1.8250\n",
      "Epoch 17, Loss: 1.8012\n",
      "Epoch 18, Loss: 1.7500\n",
      "Epoch 19, Loss: 1.7072\n",
      "Epoch 20, Loss: 1.6735\n",
      "Epoch 21, Loss: 1.6438\n",
      "Epoch 22, Loss: 1.6461\n",
      "Epoch 23, Loss: 1.5986\n",
      "Epoch 24, Loss: 1.5589\n",
      "Epoch 25, Loss: 1.5573\n",
      "Epoch 26, Loss: 1.5066\n",
      "Epoch 27, Loss: 1.5204\n",
      "Epoch 28, Loss: 1.4688\n",
      "Epoch 29, Loss: 1.4529\n",
      "Epoch 30, Loss: 1.3985\n",
      "Epoch 31, Loss: 1.4044\n",
      "Epoch 32, Loss: 1.3603\n",
      "Epoch 33, Loss: 1.3986\n",
      "Epoch 34, Loss: 1.3354\n",
      "Epoch 35, Loss: 1.3598\n",
      "Epoch 36, Loss: 1.3008\n",
      "Epoch 37, Loss: 1.2834\n",
      "Epoch 38, Loss: 1.2619\n",
      "Epoch 39, Loss: 1.2387\n",
      "Epoch 40, Loss: 1.2165\n",
      "Epoch 41, Loss: 1.2173\n",
      "Epoch 42, Loss: 1.1834\n",
      "Epoch 43, Loss: 1.1509\n",
      "Epoch 44, Loss: 1.1641\n",
      "Epoch 45, Loss: 1.1238\n",
      "Epoch 46, Loss: 1.0942\n",
      "Epoch 47, Loss: 1.0969\n",
      "Epoch 48, Loss: 1.0629\n",
      "Epoch 49, Loss: 1.0524\n",
      "Epoch 50, Loss: 1.0720\n",
      "Epoch 51, Loss: 1.0513\n",
      "Epoch 52, Loss: 0.9886\n",
      "Epoch 53, Loss: 1.0007\n",
      "Epoch 54, Loss: 1.0437\n",
      "Epoch 55, Loss: 1.0233\n",
      "Epoch 56, Loss: 0.9687\n",
      "Epoch 57, Loss: 0.9280\n",
      "Epoch 58, Loss: 0.9127\n",
      "Epoch 59, Loss: 0.9171\n",
      "Epoch 60, Loss: 0.9066\n",
      "Epoch 61, Loss: 0.8767\n",
      "Epoch 62, Loss: 0.8531\n",
      "Epoch 63, Loss: 0.8547\n",
      "Epoch 64, Loss: 0.8723\n",
      "Epoch 65, Loss: 0.8296\n",
      "Epoch 66, Loss: 0.8081\n",
      "Epoch 67, Loss: 0.7777\n",
      "Epoch 68, Loss: 0.8067\n",
      "Epoch 69, Loss: 0.8143\n",
      "Epoch 70, Loss: 0.7393\n",
      "Epoch 71, Loss: 0.7666\n",
      "Epoch 72, Loss: 0.7954\n",
      "Epoch 73, Loss: 0.7699\n",
      "Epoch 74, Loss: 0.8037\n",
      "Epoch 75, Loss: 0.7322\n",
      "Epoch 76, Loss: 0.7425\n",
      "Epoch 77, Loss: 0.7159\n",
      "Epoch 78, Loss: 0.7244\n",
      "Epoch 79, Loss: 0.6970\n",
      "Epoch 80, Loss: 0.6561\n",
      "Epoch 81, Loss: 0.6836\n",
      "Epoch 82, Loss: 0.6656\n",
      "Epoch 83, Loss: 0.6886\n",
      "Epoch 84, Loss: 0.6563\n",
      "Epoch 85, Loss: 0.6111\n",
      "Epoch 86, Loss: 0.6090\n",
      "Epoch 87, Loss: 0.6204\n",
      "Epoch 88, Loss: 0.5992\n",
      "Epoch 89, Loss: 0.6177\n",
      "Epoch 90, Loss: 0.6198\n",
      "Epoch 91, Loss: 0.5932\n",
      "Epoch 92, Loss: 0.6254\n",
      "Epoch 93, Loss: 0.5653\n",
      "Epoch 94, Loss: 0.5685\n",
      "Epoch 95, Loss: 0.5390\n",
      "Epoch 96, Loss: 0.6039\n",
      "Epoch 97, Loss: 0.5674\n",
      "Epoch 98, Loss: 0.6957\n",
      "Epoch 99, Loss: 0.6554\n",
      "Epoch 100, Loss: 0.5509\n",
      "Epoch 101, Loss: 0.5953\n",
      "Epoch 102, Loss: 0.5357\n",
      "Epoch 103, Loss: 0.4909\n",
      "Epoch 104, Loss: 0.5045\n",
      "Epoch 105, Loss: 0.5002\n",
      "Epoch 106, Loss: 0.4639\n",
      "Epoch 107, Loss: 0.4519\n",
      "Epoch 108, Loss: 0.4642\n",
      "Epoch 109, Loss: 0.4488\n",
      "Epoch 110, Loss: 0.4509\n",
      "Epoch 111, Loss: 0.4516\n",
      "Epoch 112, Loss: 0.4568\n",
      "Epoch 113, Loss: 0.4825\n",
      "Epoch 114, Loss: 0.5051\n",
      "Epoch 115, Loss: 0.4589\n",
      "Epoch 116, Loss: 0.4526\n",
      "Epoch 117, Loss: 0.4188\n",
      "Epoch 118, Loss: 0.4463\n",
      "Epoch 119, Loss: 0.4064\n",
      "Epoch 120, Loss: 0.4253\n",
      "Epoch 121, Loss: 0.4361\n",
      "Epoch 122, Loss: 0.4749\n",
      "Epoch 123, Loss: 0.4008\n",
      "Epoch 124, Loss: 0.4306\n",
      "Epoch 125, Loss: 0.4568\n",
      "Epoch 126, Loss: 0.4105\n",
      "Epoch 127, Loss: 0.4124\n",
      "Epoch 128, Loss: 0.4087\n",
      "Epoch 129, Loss: 0.4480\n",
      "Epoch 130, Loss: 0.3559\n",
      "Epoch 131, Loss: 0.3895\n",
      "Epoch 132, Loss: 0.3493\n",
      "Epoch 133, Loss: 0.3786\n",
      "Epoch 134, Loss: 0.3627\n",
      "Epoch 135, Loss: 0.4185\n",
      "Epoch 136, Loss: 0.3858\n",
      "Epoch 137, Loss: 0.3317\n",
      "Epoch 138, Loss: 0.3785\n",
      "Epoch 139, Loss: 0.3242\n",
      "Epoch 140, Loss: 0.3585\n",
      "Epoch 141, Loss: 0.4245\n",
      "Epoch 142, Loss: 0.4018\n",
      "Epoch 143, Loss: 0.3713\n",
      "Epoch 144, Loss: 0.4050\n",
      "Epoch 145, Loss: 0.3895\n",
      "Epoch 146, Loss: 0.3468\n",
      "Epoch 147, Loss: 0.3106\n",
      "Epoch 148, Loss: 0.3000\n",
      "Epoch 149, Loss: 0.3506\n",
      "Epoch 150, Loss: 0.3302\n",
      "Epoch 151, Loss: 0.3165\n",
      "Epoch 152, Loss: 0.3364\n",
      "Epoch 153, Loss: 0.3509\n",
      "Epoch 154, Loss: 0.3685\n",
      "Epoch 155, Loss: 0.3624\n",
      "Epoch 156, Loss: 0.3700\n",
      "Epoch 157, Loss: 0.3581\n",
      "Epoch 158, Loss: 0.3832\n",
      "Epoch 159, Loss: 0.3181\n",
      "Epoch 160, Loss: 0.2938\n",
      "Epoch 161, Loss: 0.2898\n",
      "Epoch 162, Loss: 0.2692\n",
      "Epoch 163, Loss: 0.3120\n",
      "Epoch 164, Loss: 0.2471\n",
      "Epoch 165, Loss: 0.2476\n",
      "Epoch 166, Loss: 0.2579\n",
      "Epoch 167, Loss: 0.3555\n",
      "Epoch 168, Loss: 0.3492\n",
      "Epoch 169, Loss: 0.3476\n",
      "Epoch 170, Loss: 0.3677\n",
      "Epoch 171, Loss: 0.4567\n",
      "Epoch 172, Loss: 0.3721\n",
      "Epoch 173, Loss: 0.2970\n",
      "Epoch 174, Loss: 0.3227\n",
      "Epoch 175, Loss: 0.2351\n",
      "Epoch 176, Loss: 0.2404\n",
      "Epoch 177, Loss: 0.2707\n",
      "Epoch 178, Loss: 0.3458\n",
      "Epoch 179, Loss: 0.3065\n",
      "Epoch 180, Loss: 0.3096\n",
      "Epoch 181, Loss: 0.2329\n",
      "Epoch 182, Loss: 0.2592\n",
      "Epoch 183, Loss: 0.2207\n",
      "Epoch 184, Loss: 0.2320\n",
      "Epoch 185, Loss: 0.2582\n",
      "Epoch 186, Loss: 0.2727\n",
      "Epoch 187, Loss: 0.2494\n",
      "Epoch 188, Loss: 0.2913\n",
      "Epoch 189, Loss: 0.3002\n",
      "Epoch 190, Loss: 0.2850\n",
      "Epoch 191, Loss: 0.2629\n",
      "Epoch 192, Loss: 0.2990\n",
      "Epoch 193, Loss: 0.2693\n",
      "Epoch 194, Loss: 0.2356\n",
      "Epoch 195, Loss: 0.2657\n",
      "Epoch 196, Loss: 0.2676\n",
      "Epoch 197, Loss: 0.2603\n",
      "Epoch 198, Loss: 0.2749\n",
      "Epoch 199, Loss: 0.2565\n",
      "Epoch 200, Loss: 0.2182\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0  # để đếm tổng số mẫu hợp lệ\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Bỏ qua ảnh có nhãn -1 (do lỗi đọc ảnh hoặc sai định dạng tên file)\n",
    "        mask = labels != -1\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        images, labels = images[mask], labels[mask]\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "    avg_loss = running_loss / total if total > 0 else 0\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de59ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi đọc ảnh D:\\Test\\data.2025\\21151445fd63ff79440449974f17109d.jpg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\21151445fd63ff79440449974f17109d.jpg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\2c18ee0e7cea8354149df435532d74ae.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\2c18ee0e7cea8354149df435532d74ae.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\3a816aa78f56749a0822d700ff560924.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\3a816aa78f56749a0822d700ff560924.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\4abc1b5dcf1be1de6503dc072e132fa0.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\4abc1b5dcf1be1de6503dc072e132fa0.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\70ebf0bec317006017a54d6c9172af45.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\70ebf0bec317006017a54d6c9172af45.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\8eeee227b3f244e980b747387bc79bf2.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\8eeee227b3f244e980b747387bc79bf2.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\9e748b9617e26b90011f8d7c3f8a7eee.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\9e748b9617e26b90011f8d7c3f8a7eee.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\a008f795ae8498751f2e5feeb0b73387.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\a008f795ae8498751f2e5feeb0b73387.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\ce2388179ec73203a60d8efedd04e0f1.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\ce2388179ec73203a60d8efedd04e0f1.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\d4b080c6ce4933f1199fad7f75e7d112.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\d4b080c6ce4933f1199fad7f75e7d112.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\e21dcb1cb0571a21a013b4232d1b6a13.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\e21dcb1cb0571a21a013b4232d1b6a13.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\f7679411e290bfd8dc90b3eadb57460a.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\f7679411e290bfd8dc90b3eadb57460a.jpeg'\n",
      "Lỗi đọc ảnh D:\\Test\\data.2025\\ffd4f9df7163f55474a0182265c8d810.jpeg: cannot identify image file 'D:\\\\Test\\\\data.2025\\\\ffd4f9df7163f55474a0182265c8d810.jpeg'\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for images, paths in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        for path, pred in zip(paths, preds):\n",
    "            filename = os.path.basename(path)\n",
    "            results.append([filename, int(pred)])\n",
    "\n",
    "with open('ANN_predictions.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['filename', 'prediction'])\n",
    "    writer.writerows(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
